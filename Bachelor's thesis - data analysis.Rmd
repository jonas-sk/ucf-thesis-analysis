---
title: "UCF Bachelor's Thesis"
subtitle: "Analysis of Coded Data"
output: html_notebook
---

Installing `rtemis`, a library for advanced machine learning which used here for the additive trees, as well as necessary dependencies.

```{r eval=FALSE}
install.packages("remotes")
remotes::install_github("egenn/rtemis")
install.packages(c("e1071", "gbm", "glmnet", "pbapply", "plyr", "ranger", "rpart", "data.tree", "DiagrammeR", "missRanger", "plotly", "DiagrammeRsvg", "rsvg")) #Additional dependencies
```


```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(rtemis)
#Loaded sparately to export the plots
library(DiagrammeRsvg)
library(rsvg)
```

# Pilot

Importing the Atlas.ti dataset. (NB: I changed the document number for the second holding of Finogenov to make distinguishing easier)

```{r}
library(readxl)
pilot <- read_excel("pilot coding data.xlsx")
```

Merging the observations spread out over multiple rows into one.

```{r}
pilot2 <- pilot %>% 
  select(D, 3, 13:70) %>% 
  group_by(D) %>% 
  summarise_all(list(~ toString(unique(na.omit(.)))))
```

Getting summary statistics.

```{r}
pilot2 %>% 
  summarise_all(list(~n()))

pilot_subset <- pilot2 %>% 
  select(D, Q49:Q53) %>%  
  pivot_longer(names_to = "var", values_to = "val", cols = c(everything(), -D))

pilot_subset %>% 
  group_by(var, val) %>% 
  summarise_all(list(~length(.)))
```

---

# Tidying the Final Dataset

Importing the Excel coded cases dataset:

```{r}
library(readxl)
cases_raw <- read_excel("case codings database.xlsx")
```

Removing the explanation for each level, turning ordinal variables into ordinal factors, and the remaining ones into normal factors:

```{r}
cases <- cases_raw %>% 
  select(gc_dec:l_train) %>% 
  mutate_all(list(~ str_replace(., "\\s=\\s.*", ""))) %>% 
  mutate(
    scrutiny = scrutiny     %>% as.numeric() %>% as.ordered(),
    f_prev = f_prev         %>% as.numeric() %>% as.ordered(),
    f_dispute = f_dispute   %>% as.numeric() %>% as.ordered(),
    uof_deaths = uof_deaths %>% as.numeric() %>% as.ordered(),
    t_who = t_who           %>% as.numeric() %>% as.ordered(),
    t_nature = t_nature     %>% as.numeric() %>% as.ordered(),
    uof_sa = uof_sa         %>% as.numeric() %>% as.ordered(),
    uof_nature = uof_nature %>% as.numeric() %>% as.ordered(),
    o_control = o_control   %>% as.numeric() %>% as.ordered()
  )  %>% 
  mutate_all(list(~ as_factor(.)))

cases <- cbind(select(cases_raw, ID:respondent), cases)
```

# Collapsing Variables and Categories

```{r}
IVcases <- cases %>% select(scrutiny:l_train) #Only want to analyze and reduce the IVs
```

Checking if there are any superfluous levels.

```{r}
IVcases %>% sapply(table)
IVcases %>% sapply(table) %>% sapply(prop.table)
```

There are multiple methods possible to achieve this. Principally, these can be divided into factor analysis and principal component analysis (PCA). Both have variations that are compatible with categorical data. I pick PCA here because, conceptually, it focuses on reducing the number of dimensions (variables) while factor analysis is focused on uncovering latent factors. Within the realm of non-linear PCA, I picked multiple factor analysis (MFA) because it is well suited for grouped data (like in my case)

```{r}
library(FactoMineR)
library(factoextra)


MFAcases <- MFA(IVcases, group = c(6, 14, 5, 11, 3), #Groups based on coding form
                type = rep("n", 5), 
                name.group = c("assessment", "exceptions", "force", "operation", "law"))
```

Using Chi-square and Cramer's V to find relations of dependence between the cateogrical variables

# Preparing for the Use of Decision Trees

Create the datasets for each of our four outcome variables. This involves putting the outcome variable as last column and recoding the factor such that the "positive" outcome (i.e. a violation) is the first level of the factor. Furthermore, the three other outcome variables are turned into binomial variables with one positive (violation) level and one negative (no violation, not related or uncertain) level. 

```{r}
cases.viol <- cases %>% 
  select(scrutiny:l_train, h_viol) %>% 
  mutate(h_viol = factor(h_viol, levels = c(1, 0)))
cases.force <- cases %>%   
  select(scrutiny:l_train, h_force) %>% 
  mutate(h_force = recode(h_force, `0` = 0, `1` = 0, `-88` = 0, `2`= 1)) %>% 
  mutate(h_force = factor(h_force, levels = c(1, 0)))
cases.op <- cases %>% 
  select(scrutiny:l_train, h_operation) %>% 
  mutate(h_operation = recode(h_operation, `0` = 0, `1` = 0, `-88` = 0, `2`= 1)) %>% 
  mutate(h_operation = factor(h_operation, levels = c(1, 0)))
cases.law <- cases %>% 
  select(scrutiny:l_train, h_law) %>% 
  mutate(h_law = recode(h_law, `0` = 0, `1` = 0, `-88` = 0, `2`= 1)) %>% 
  mutate(h_law = factor(h_law, levels = c(1, 0)))
```

# Using Decision Trees

## Model Selection and Assessment

Perform a nested cross-validation for hyperparameter tuning (model selection) and model assessment. A 10-fold cross-validation is performed to test model generalizability. Within each resample, another 10-fold cross-validation is performed to tune the gamma hyperparameter between four different options. In total, 1600 models are thus run. 

```{r eval=FALSE}
cases.viol.tree <- elevate(cases.viol, mod = "addtree",
                           resampler = "kfold", n.resamples = 10,
                           grid.resample.rtset = rtset.resample("kfold", 10),
                           gamma = c(0.1, 0.3, 0.5, 0.7, 0.9),
                           learning.rate = 0.001,
                           seed = 2020)
saveRDS(cases.viol.tree, "cases-viol-tree.rds")

cases.force.tree <- elevate(cases.force, mod = "addtree",
                           resampler = "kfold", n.resamples = 10,
                           grid.resample.rtset = rtset.resample("kfold", 10),
                           gamma = c(0.1, 0.3, 0.5, 0.7, 0.9),
                           learning.rate = 0.001,
                           seed = 2020)
saveRDS(cases.force.tree, "cases-force-tree.rds")

cases.op.tree <- elevate(cases.op, mod = "addtree",
                           resampler = "kfold", n.resamples = 10,
                           grid.resample.rtset = rtset.resample("kfold", 10),
                           gamma = c(0.1, 0.3, 0.5, 0.7, 0.9),
                           learning.rate = 0.001,
                           seed = 2020)
saveRDS(cases.op.tree, "cases-op-tree.rds")

cases.law.tree <- elevate(cases.law, mod = "addtree",
                           resampler = "kfold", n.resamples = 10,
                           grid.resample.rtset = rtset.resample("kfold", 10),
                           gamma = c(0.1, 0.3, 0.5, 0.7, 0.9),
                           learning.rate = 0.001,
                           seed = 2020)
saveRDS(cases.law.tree, "cases-law-tree.rds")

```

Read the AddTrees in from the saved file because re-executing the model run for knitting is too computationally expensive:

```{r}
cases.viol.tree <- readRDS("cases-viol-tree.rds")
cases.force.tree <- readRDS("cases-force-tree.rds")
cases.op.tree <- readRDS("cases-op-tree.rds")
cases.law.tree <- readRDS("cases-law-tree.rds")
```

Getting some summaries on the models: 

```{r}
cases.viol.tree$plot(main = "AddTree Violation: Aggregated Test Performance") %>% export_svg()
cases.force.tree$plot(filename = "cases-force-tree-plot.jpg")
cases.op.tree$plot(filename = "cases-op-tree-plot.jpg")
cases.law.tree$plot(filename = "cases-law-tree-plot.jpg")
```

```{r}
message("h_viol model: \n")
cases.viol.tree$describe()
message("\n h_force model: \n")
cases.force.tree$describe()
message("\n h_operation model: \n")
cases.op.tree$describe()
message("\n h_law model: \n")
cases.law.tree$describe()
```


After running the models, we would now like to extract the respective information. This encompasses the values in the list below, which includes the  aggregated values of the evaluation measures and the hyperparameters picked.

* Balanced Accuracy
* Sensitivity (recall)
* Specificity
* Precision (positive predictive value)
* Negative predictive value
* Gamma $\gamma$ ($= \frac{\lambda}{1 + \lambda}$)

Extracting the evaluation measures:

```{r}
cases.viol.tree$error.test.repeats
cases.force.tree$error.test.repeats
cases.op.tree$error.test.repeats
cases.law.tree$error.test.repeats
```

Side note: The difference between `tree$error.test.res.aggr`and `tree$error.test.res.mean`: Latter just takes the mean of the results of the 10 repeats while former aggregates the specific counts into a confusion matrix and then calculates the evaluation measures. The (theoretical) difference between `tree$error.test.repeats` and `tree$error.test.res.aggr`: Former relates to the repeats (default: `n.repeats` = 1) of the resampling process (summarizing those values with `... .mean` and `... .sd`) while `error.test.res` concerns the resamples in each repeat with `aggr` listing the aggregate values within each repeat (which is why they have the `$elevate.ADDTREE.repeat1` substructure) .

Extracting the best hyperparameters:

```{r}
cases.viol.tree$parameters$best.tune$elevate.ADDTREE.repeat1 %>% select(gamma) %>% table()
cases.force.tree$parameters$best.tune$elevate.ADDTREE.repeat1 %>% select(gamma) %>% table()
cases.op.tree$parameters$best.tune$elevate.ADDTREE.repeat1 %>% select(gamma) %>% table()
cases.law.tree$parameters$best.tune$elevate.ADDTREE.repeat1 %>% select(gamma) %>% table()

cases.viol.tree$parameters$best.tune$elevate.ADDTREE.repeat1 %>% summarize(mean(gamma), median(gamma))
cases.force.tree$parameters$best.tune$elevate.ADDTREE.repeat1 %>% summarize(mean(gamma), median(gamma))
cases.op.tree$parameters$best.tune$elevate.ADDTREE.repeat1 %>% summarize(mean(gamma), median(gamma))
cases.law.tree$parameters$best.tune$elevate.ADDTREE.repeat1 %>% summarize(mean(gamma), median(gamma))
```

Based on the median hyperparameter, I pick $\gamma = 0.4$ for every model but `h_operation` for which I choose $\gamma = 0.7$ for the full model.

## Full models for Prediction and Visualization


Full model for `h_viol`:

```{r}
cases.viol.tree.full <- s.ADDTREE(cases.viol, gamma = 0.4, learning.rate = 0.001, seed = 2020)
saveRDS(cases.viol.tree.full, "cases-viol-tree-full.rds")

cases.viol.tree.full.viz <- dplot3.addtree(cases.viol.tree.full, fontname = "calibri")
cases.viol.tree.full.viz %>% 
  export_svg() %>% charToRaw() %>% 
  rsvg_svg(file = "cases-viol-tree-full.svg")
```

Full model for `h_force`:

```{r}
cases.force.tree.full <- s.ADDTREE(cases.force, gamma = 0.4, learning.rate = 0.001, seed = 2020)
saveRDS(cases.force.tree.full, "cases-force-tree-full.rds")

cases.force.tree.full.viz <- dplot3.addtree(cases.force.tree.full, fontname = "calibri")
cases.force.tree.full.viz %>% 
  export_svg() %>% charToRaw() %>% 
  rsvg_svg(file = "cases-force-tree-full.svg")
```

Full model for `h_operation`:

```{r}
cases.op.tree.full <- s.ADDTREE(cases.op, gamma = 0.4, learning.rate = 0.001, seed = 2020)
saveRDS(cases.op.tree.full, "cases-op-tree-full.rds")

cases.op.tree.full.viz <- dplot3.addtree(cases.op.tree.full, fontname = "calibri")
cases.op.tree.full.viz %>% 
  export_svg() %>% charToRaw() %>% 
  rsvg_svg(file = "cases-op-tree-full.svg")
```

Full model for `h_law`:

```{r}
cases.law.tree.full <- s.ADDTREE(cases.law, gamma = 0.4, learning.rate = 0.001, seed = 2020)
saveRDS(cases.law.tree.full, "cases-law-tree-full.rds")

cases.law.tree.full.viz <- dplot3.addtree(cases.law.tree.full, fontname = "calibri")
cases.law.tree.full.viz %>% 
  export_svg() %>% charToRaw() %>% 
  rsvg_svg(file = "cases-law-tree-full.svg")
```

# Experiments

```{r}
cases_test <- elevate(cases.viol, mod = "addtree",
                           resampler = "kfold", n.resamples = 10,
                           gamma = 0.3,
                           learning.rate = 0.001,
                           n.cores = 4,
                           seed = 2020)
```

```{r}
cases_test <- elevate(cases.viol, mod = "addtree",
                           resampler = "kfold", 
                           n.resamples = 2, n.repeats = 2,
                           gamma = 0.3,
                           learning.rate = 0.001,
                           n.cores = 4,
                           seed = 2020)

```


```{r}
cases_test.tree <- read_csv("cases_test.csv") %>% 
  preprocess(numeric2factor = TRUE) %>% 
  elevate(mod = "addtree", resampler = "kfold", n.resamples = 2, upsample = TRUE,
          grid.resample.rtset = rtset.resample("kfold", 2),
          gamma = c(0.5, 1))

cases_test.tree <- read_csv("cases_test.csv") %>% 
  preprocess(numeric2factor = TRUE) %>% 
  s.ADDTREE(outdir = "test")

dplot3.addtree(cases_test.tree$mod$elevate.ADDTREE.repeat1$ADDTREE2$mod1)
cases_test.tree$plotVarImp()
dplot3.addtree(cases_test2.tree)
plot(cases_test.tree$mod$addtree.pruned)
```



```{r}
cases_test <- cases %>% select(scrutiny:l_train, h_viol)
# cases_test <- cases_raw %>%
#   select(scrutiny:l_train, h_viol) %>%
#   mutate_all(list(~ str_replace(., "\\s=\\s.*", ""))) %>%
#   mutate_all(list(~ dplyr::recode(.,`-99` = "99",
#                                   `-88` = "88",
#                                    `-77` = "77"
#                                   )))
checkData(cases_test)
cases_test2 <- preprocess(cases_test, character2factor = TRUE)
# write_csv(cases_test2, "cases_test.csv")

# cases_test <- cases
# cases_test$violation <- cases$h_viol
# cases_test2 <- cases_test %>% 
#   mutate(o_evac = recode(o_evac, "0" = "1"), o_distinct = recode(o_distinct, "0" = "1")) %>% 
#   mutate(o_evac = replace_na(o_evac, 0), o_distinct = replace_na(o_distinct, 0)) %>% 
#   preprocess(impute = TRUE, character2factor = TRUE, impute.type = "missForest")


checkData(cases_test2)

cases_test.tree <- s.ADDTREE(cases_test, gamma = 0.5, learning.rate = 0.0001, upsample = TRUE)
dplot3.addtree(cases_test.tree)
print(cases_test.tree$mod$addtree.pruned, "Estimate")

#With testing
res <- resample(cases_test, n.resamples = 10, resampler = "kfold")
cases_test.train <- cases_test[res$Fold_2, ]
cases_test.test <- cases_test[-res$Fold_2, ]
cases_test.tree <- s.ADDTREE(x = cases_test.train, x.test = cases_test.test, gamma = 2, learning.rate = 0.01)
dplot3.addtree(cases_test.tree)
```

